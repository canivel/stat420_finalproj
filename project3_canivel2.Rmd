---
title: "project"
author: "Danilo Canivel(canivel2)"
date: "7/31/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, eval=FALSE}
library(lubridate)
library(cluster)
library(tidyverse)
library(caret)
library(magrittr)
library(Matrix)
```


## Read Data

```{r}
nrows = 100000
fdata = read.csv("./input/train.csv", stringsAsFactors=FALSE, nrows=nrows)
```

## Feature Engineering

```{r}
earth_radius = 6371 #in kms

sphere_dist = function(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon)
{
    #Compute distances along lat, lon dimensions
    dlat = dropoff_lat - pickup_lat
    dlon = dropoff_lon - pickup_lon
    
    #Compute  distance
    a = sin(dlat/2.0)**2 + cos(pickup_lat) * cos(dropoff_lat) * sin(dlon/2.0)**2
    
    return (2 * earth_radius * asin(sqrt(a)))
    
} 

features_eng = function(data, istrain=TRUE){
  
  if(istrain == TRUE){
    data = data[complete.cases(data),]
    # Remove Negative Fare and No Passenger and some places that does not exist
    data = data[(data$fare_amount > 0 & data$fare_amount <= 500),]
    data = data[(data$pickup_longitude > -80 && data$pickup_longitude < -70),]
    data = data[(data$pickup_latitude > 35 && data$pickup_latitude < 45),]
    data = data[(data$dropoff_longitude > -80 && data$dropoff_longitude < -70),]
    data = data[(data$dropoff_latitude > 35 && data$dropoff_latitude < 45),]
    #only if passengers are between 1 and 9
    data = data[(data$passenger_count > 0 && data$passenger_count < 10),]
  }
  
  # Convert to datetime obj
  data$pickup_datetime = as_datetime(data$pickup_datetime, tz="UTC")

  # factorization
  data$year = as.factor(year(data$pickup_datetime))
  data$month = as.factor(month(data$pickup_datetime))
  data$day = as.factor(day(data$pickup_datetime))
  data$weekday = as.factor(weekdays(data$pickup_datetime))

  #factor time of the day
  hour = hour(data$pickup_datetime)
  data$time = as.factor(ifelse(hour < 7, "Overnight", 
                               ifelse(hour < 11, "Morning", 
                                      ifelse(hour < 16, "Noon",
                                             ifelse(hour < 20, "Evening",
                                                    ifelse(hour < 23, "night", "overnight")
                        )))))
  # convert to radius position
  data$pickup_latitude = (data$pickup_latitude * pi)/180
  data$dropoff_latitude = (data$dropoff_latitude * pi)/180
  data$dropoff_longitude = (data$dropoff_longitude * pi)/180
  data$pickup_longitude = (data$pickup_longitude * pi)/180 
  data$dropoff_longitude = ifelse(is.na(data$dropoff_longitude) == TRUE, 0,data$dropoff_longitude)
  data$pickup_longitude = ifelse(is.na(data$pickup_longitude) == TRUE, 0,data$pickup_longitude)
  data$pickup_latitude = ifelse(is.na(data$pickup_latitude) == TRUE, 0,data$pickup_latitude)
  data$dropoff_latitude = ifelse(is.na(data$dropoff_latitude) == TRUE, 0,data$dropoff_latitude)

  # compare locations
  data$dlat = data$dropoff_latitude - data$pickup_latitude
  data$dlon = data$dropoff_longitude - data$pickup_longitude 
  
  #Compute haversine distance
  
  data$hav = sin(data$dlat/2.0)**2 + cos(data$pickup_latitude) * cos(data$dropoff_latitude) * sin(data$dlon/2.0)**2
  data$haversine = round(x = 2 * earth_radius * asin(sqrt(data$hav)), digits = 4)
  print(dim(data))
  
  #Compute Bearing distance
  data$dlon = data$pickup_longitude - data$dropoff_longitude
  data$bearing = atan2(sin(data$dlon * cos(data$dropoff_latitude)), cos(data$pickup_latitude) * sin(data$dropoff_latitude) - sin(data$pickup_latitude) * cos(data$dropoff_latitude) * cos(data$dlon))

  #Some point of interest where people most use taxis in NYC
  jfk_coord_lat = (40.639722 * pi)/180
  jfk_coord_long = (-73.778889 * pi)/180
  ewr_coord_lat = (40.6925 * pi)/180
  ewr_coord_long = (-74.168611 * pi)/180
  lga_coord_lat = (40.77725 * pi)/180
  lga_coord_long = (-73.872611 * pi)/180
  liberty_statue_lat = (40.6892 * pi)/180
  liberty_statue_long = (-74.0445 * pi)/180
  nyc_lat = (40.7141667 * pi)/180
  nyc_long = (-74.0063889 * pi)/180
  
  #calculate distances radius for the POI
  data$JFK_dist = sphere_dist(data$pickup_latitude, data$pickup_longitude, jfk_coord_lat, jfk_coord_long) + sphere_dist(jfk_coord_lat, jfk_coord_long, data$dropoff_latitude, data$dropoff_longitude)
  data$EWR_dist = sphere_dist(data$pickup_latitude, data$pickup_longitude, ewr_coord_lat, ewr_coord_long) +  sphere_dist(ewr_coord_lat, ewr_coord_long, data$dropoff_latitude, data$dropoff_longitude)
  data$lga_dist = sphere_dist(data$pickup_latitude, data$pickup_longitude, lga_coord_lat, lga_coord_long) + sphere_dist(lga_coord_lat, lga_coord_long, data$dropoff_latitude, data$dropoff_longitude) 
  data$sol_dist = sphere_dist(data$pickup_latitude, data$pickup_longitude, liberty_statue_lat, liberty_statue_long) + sphere_dist(liberty_statue_lat, liberty_statue_long, data$dropoff_latitude, data$dropoff_longitude)
  data$nyc_dist = sphere_dist(data$pickup_latitude, data$pickup_longitude, nyc_lat, nyc_long) + sphere_dist(nyc_lat, nyc_long, data$dropoff_latitude, data$dropoff_longitude)
  
  #remove some columns
  drops <- c("pickup_datetime")
  data = data[, !(names(data) %in% drops)]
  print(dim(data))
  return (data)
  
}
```

```{r}
fdata = features_eng(data = fdata)
```

```{r}
### Outlier Pickup locations 
  fdata = fdata[fdata$pickup_longitude < median(fdata$pickup_longitude) + 1.5 * IQR( fdata$pickup_longitude) &
              fdata$pickup_longitude > median(fdata$pickup_longitude - 1.5 * IQR(fdata$pickup_longitude)) &
              fdata$pickup_latitude < median(fdata$pickup_latitude) + 1.5 * IQR(fdata$pickup_latitude) &
              fdata$pickup_latitude > median(fdata$pickup_latitude) - 1.5 * IQR(fdata$pickup_latitude),]
  print(dim(fdata))
  # Outlier Dropoff locations
  fdata = fdata[fdata$dropoff_longitude < median(fdata$dropoff_longitude) + 1.5 * IQR(fdata$dropoff_longitude) &
              fdata$dropoff_longitude > median(fdata$dropoff_longitude - 1.5 * IQR(fdata$dropoff_longitude)) &
              fdata$dropoff_latitude < median(fdata$dropoff_latitude) + 1.5 * IQR(fdata$dropoff_latitude) &
              fdata$dropoff_latitude > median(fdata$dropoff_latitude) - 1.5 * IQR(fdata$dropoff_latitude),]
  print(dim(fdata))
  # Outlier Fare Amount
  fdata = fdata[fdata$fare_amount < median(fdata$fare_amount) + 1.5 * IQR(fdata$fare_amount),]
```



```{r}
inds = sample.int(nrow(fdata), size=nrow(fdata) * 0.9) 
train = fdata[inds,]
test = fdata[-inds,]
dim(train)
dim(test)
head(train)
```

```{r}
calc_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

calc_rmse2 = function(model, data){
  sqrt(sum((data$fare_amount - predict(model, newdata=data))^2) / nrow(data))
}
```


## Multiple Linear Regression

```{r}
colnames(fdata)
```



```{r}
m_additive = lm(fare_amount ~ dropoff_longitude + dropoff_latitude + passenger_count + day + weekday + time + dlat + dlon + haversine + bearing, train)
```

```{r}
m_additive_top_xgb = lm(fare_amount ~ haversine * pickup_datetime * dropoff_longitude + dlat + dropoff_latitude + pickup_longitude + bearing + day + weekday + time, train)
```

```{r}
calc_rmse(m_additive)
calc_rmse2(m_additive, test)
```

```{r}
calc_rmse(m_additive_top_xgb)
calc_rmse2(m_additive_top_xgb, test)
```

```{r}
anova(m_additive_top_xgb, m_additive)
```


```{r}
#n = length(resid(m_additive))
#m_add_mod_back_bic = step(m_additive, direction = "backward", k = log(n))
```

```{r}
library('faraway')
round(vif(m_additive), 3)

```


```{r}
test_kaggle = read.csv("./input/test.csv", stringsAsFactors=FALSE)
test_kaggle = features_eng(data = test_kaggle, FALSE)
```

```{r}
#---------------------------
cat("Making submission file...\n")

read.csv("./input/sample_submission.csv") %>%  
  mutate(fare_amount = predict(m_additive_top_xgb, test_kaggle)) %>%
  write_csv("sub_lm_additive_6.csv")
```

```{r}
library(xgboost)
target = fdata$fare_amount

X_train = train %>% select (- fare_amount)
X_test = test %>% select (- fare_amount)

dvalid = xgb.DMatrix(data = data.matrix(X_test), label = target[-inds])
dtrain = xgb.DMatrix(data = data.matrix(X_train), label = target[inds])

p = list(objective = "reg:linear",
          eval_metric = "rmse",
          max_depth = 8 ,
          eta = .5, #.05
          subsample=1,
          colsample_bytree=0.8,
          num_boost_round=1000,
          nrounds = 1000)

set.seed(0)
m_xgb = xgb.train(p, dtrain, p$nrounds, list(val = dvalid), print_every_n = 10, early_stopping_rounds = 50)
```
##XGB Importance
```{r}
xgb.importance(colnames(dtrain), model = m_xgb)
```

```{r}
xgb.save(m_xgb, "client/m_xgb_1.model")
```


```{r}
#---------------------------
cat("Making submission file...\n")

read.csv("./input/sample_submission.csv") %>%  
  mutate(fare_amount = predict(m_xgb, data.matrix(test_kaggle))) %>%
  write_csv("sub_xgb_2.csv")
```